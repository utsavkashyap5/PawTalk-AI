# ğŸ• FurSpeak AI

<div align="center">
  <img src="assets/images/app_logo.png" alt="FurSpeak AI Logo" width="200"/>
  
  [![Flutter](https://img.shields.io/badge/Flutter-3.x-blue.svg)](https://flutter.dev)
  [![Python](https://img.shields.io/badge/Python-3.8+-green.svg)](https://python.org)
  [![FastAPI](https://img.shields.io/badge/FastAPI-0.68.0+-blue.svg)](https://fastapi.tiangolo.com)
  [![YOLOv5](https://img.shields.io/badge/YOLOv5-Latest-orange.svg)](https://github.com/ultralytics/yolov5)
  [![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
  [![CI/CD](https://github.com/Abhijeet999-beep/FurSpeak-AI_Android_Build/actions/workflows/ci.yml/badge.svg)](https://github.com/Abhijeet999-beep/FurSpeak-AI_Android_Build/actions/workflows/ci.yml)
  [![Codecov](https://codecov.io/gh/Abhijeet999-beep/FurSpeak-AI_Android_Build/branch/main/graph/badge.svg)](https://codecov.io/gh/Abhijeet999-beep/FurSpeak-AI_Android_Build)
  [![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)
</div>

## ğŸŒŸ Overview

FurSpeak AI is an innovative mobile application that uses artificial intelligence to detect and interpret dog emotions through image and video analysis. Our app helps pet owners better understand their furry friends by providing real-time emotion detection and historical insights.

### âœ¨ Key Features

- ğŸ¯ Real-time dog emotion detection
- ğŸ“¸ Image and video analysis
- ğŸ“Š Emotion history tracking
- ğŸ‘¤ User profiles and authentication
- ğŸŒ™ Offline mode support
- ğŸ”„ Cross-device synchronization

## ğŸš€ Getting Started

### Prerequisites

- Flutter SDK (3.x or higher)
- Python 3.8+
- Git
- Android Studio / Xcode (for mobile development)

### Installation

1. Clone the repository
   ```bash
   git clone https://github.com/Abhijeet999-beep/FurSpeak-AI_Android_Build.git
   cd FurSpeak-AI_Android_Build
   ```

2. Frontend Setup
   ```bash
   # Install Flutter dependencies
   flutter pub get
   
   # Run the app
   flutter run
   ```

3. Backend Setup
   ```bash
   # Create virtual environment
   python -m venv venv
   
   # Activate virtual environment
   # Windows
   .\venv\Scripts\activate
   # Linux/Mac
   source venv/bin/activate
   
   # Install dependencies
   pip install -r backend/requirements.txt
   
   # Start the server
   cd backend
   uvicorn main:app --reload
   ```

## ğŸ› ï¸ Tech Stack

### Frontend
- Flutter
- Riverpod (State Management)
- Hive (Local Storage)
- Supabase (Backend as a Service)

### Backend
- FastAPI
- YOLOv11 (ML Model)
- OpenCV
- PyTorch

## ğŸ“¸ App Screenshots

Here are some screenshots of the FurSpeak AI app:

<div align="center">
  <img src="https://raw.githubusercontent.com/Abhijeet999-beep/FurSpeak-AI_Android_Build/master/assets/screenshots/Screenshot_1.jpg" width="200"/>
  <img src="https://raw.githubusercontent.com/Abhijeet999-beep/FurSpeak-AI_Android_Build/master/assets/screenshots/Screenshot_2.jpg" width="200"/>
  <img src="https://raw.githubusercontent.com/Abhijeet999-beep/FurSpeak-AI_Android_Build/master/assets/screenshots/Screenshot_3.jpg" width="200"/>
  <img src="https://raw.githubusercontent.com/Abhijeet999-beep/FurSpeak-AI_Android_Build/master/assets/screenshots/Screenshot_4.jpg" width="200"/>
  <img src="https://raw.githubusercontent.com/Abhijeet999-beep/FurSpeak-AI_Android_Build/master/assets/screenshots/Screenshot_5.jpg" width="200"/>
  <img src="https://raw.githubusercontent.com/Abhijeet999-beep/FurSpeak-AI_Android_Build/master/assets/screenshots/Screenshot_6.jpg" width="200"/>
  <img src="https://raw.githubusercontent.com/Abhijeet999-beep/FurSpeak-AI_Android_Build/master/assets/screenshots/Screenshot_7.jpg" width="200"/>
  <img src="https://raw.githubusercontent.com/Abhijeet999-beep/FurSpeak-AI_Android_Build/master/assets/screenshots/Screenshot_8.jpg" width="200"/>
  <img src="https://raw.githubusercontent.com/Abhijeet999-beep/FurSpeak-AI_Android_Build/master/assets/screenshots/Screenshot_9.jpg" width="200"/>
</div>
## ğŸ—ï¸ Project Structure

```
furspeak-ai/
â”œâ”€â”€ lib/                    # Flutter frontend
â”‚   â”œâ”€â”€ config/            # App configuration
â”‚   â”œâ”€â”€ data/              # Data layer
â”‚   â”œâ”€â”€ models/            # Data models
â”‚   â”œâ”€â”€ presentation/      # UI screens
â”‚   â”œâ”€â”€ services/          # Business logic
â”‚   â””â”€â”€ widgets/           # Reusable components
â”œâ”€â”€ backend/               # Python backend
â”‚   â”œâ”€â”€ models/           # ML models
â”‚   â”œâ”€â”€ detect_utils.py   # Detection utilities
â”‚   â””â”€â”€ main.py           # FastAPI server
â””â”€â”€ assets/               # Images, fonts, etc.
    â”œâ”€â”€ images/           # App logo
    â””â”€â”€ screenshots/      # App screenshots
```

## ğŸ”§ Development

### Running Tests
```bash
# Frontend tests
flutter test

# Backend tests
pytest backend/tests
```

### Code Style
```bash
# Frontend
flutter format lib/
flutter analyze

# Backend
black backend/
flake8 backend/
```

## ğŸ“ˆ Contributing

1. Fork the repository: `https://github.com/Abhijeet999-beep/FurSpeak-AI_Android_Build.git`
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- [YOLOv11](https://github.com/ultralytics/yolov5) for the ML model
- [Flutter](https://flutter.dev) for the UI framework
- [FastAPI](https://fastapi.tiangolo.com) for the backend framework
- [Supabase](https://supabase.com) for the backend services


---


